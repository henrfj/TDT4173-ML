{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee6dddb-4b6d-4c0d-a861-72d3e955cc0d",
   "metadata": {},
   "source": [
    "# Using the new found cleaning and feature engineering to experiment further with stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c39333dd-cbd0-41af-b5e7-54c51f4c4b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Specific tf libraries\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout\n",
    "# BOOST\n",
    "import xgboost\n",
    "import lightgbm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c924667-3341-4f53-bd3a-f2c1b196260e",
   "metadata": {},
   "source": [
    "## 1 - Any bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4359e99-8401-41ff-9b7f-e18130def502",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "csv_paths = []\n",
    "submission_path = \"ensemble_predictions/big_bagging_1\"\n",
    "csv_bagging(scores, csv_paths, submission_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2bfee7-5a46-46b9-b136-0f945916fcc4",
   "metadata": {},
   "source": [
    "## 2 - Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3326b638-a717-4152-9848-857516729155",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../common_utils.py\n",
    "train, test, metaData = load_all_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520abcbe-4d6a-45be-8813-6fdb7305489c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGB advisor 1 ðŸ˜Ž: all features - predicting floor price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b0f5d2d-e550-450c-ab42-de537ae04fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minMax\n"
     ]
    }
   ],
   "source": [
    "features =           [\"building_id\", # For grouping\n",
    "                      \"area_total\", \"area_kitchen\", \"area_living\", \"floor\", \"ceiling\", \"stories\", \"rooms\",\n",
    "                      \"bathrooms_private\", \"bathrooms_shared\", \"balconies\",\"loggias\", \"phones\", \"latitude\", \"longitude\", \"constructed\", # Numerical\n",
    "                     \"layout\", \"condition\", \"district\", \"material\", \"parking\", \"heating\", \"seller\", #Categorical\n",
    "                      \"windows_court\", \"windows_street\", \"new\", \"elevator_without\", \"elevator_passenger\", \"elevator_service\", \"garbage_chute\", # Bool\n",
    "                     \"street\"] #, \"address\"] # Strings\n",
    "\n",
    "all_numerical_features = [\"area_total\", \"area_kitchen\", \"area_living\", \"floor\",\n",
    "                      \"ceiling\", \"stories\", \"rooms\", \"bathrooms_private\", \"bathrooms_shared\", \"balconies\",\"loggias\", \"phones\", \"latitude\", \"longitude\", \"constructed\"]\n",
    "\n",
    "float_numerical_features = [\"area_total\", \"area_kitchen\", \"area_living\", \"ceiling\", \"latitude\", \"longitude\", \"constructed\"]\n",
    "int_numerical_features = [\"floor\", \"stories\", \"rooms\", \"bathrooms_private\", \"bathrooms_shared\", \"balconies\", \"loggias\", \"phones\"] # Ordinal categories\n",
    "\n",
    "cat_features = [\"layout\", \"condition\", \"district\", \"material\", \"parking\", \"heating\", \"seller\"] # All are non-ordinal\n",
    "\n",
    "droptable = [\"street\"]\n",
    "\n",
    "# Load data\n",
    "train, test, metaData = load_all_data()\n",
    "# Clean data. \n",
    "train_labels, train_targets, test_labels = clean_data(train, test, features, float_numerical_features, int_numerical_features, cat_features,\n",
    "                                                      log_targets=False, log_area=True, fillNan=False)\n",
    "# Add new features\n",
    "train_labels, test_labels, added_features = feature_engineering(train_labels, test_labels,\n",
    "    add_base_features=True, \n",
    "    add_bool_features=True,\n",
    "    add_weak_features=True,\n",
    "    add_dist_to_metro=True,\n",
    "    add_close_to_uni=True,\n",
    "    add_dist_to_hospital=True,\n",
    "    add_floor_features=True,\n",
    "    add_street_info=True,\n",
    "    add_some_more_features=False                                                            \n",
    "    )\n",
    "# Normalize\n",
    "train_labels, test_labels = normalize(train_labels, test_labels, float_numerical_features, scaler=\"minMax\")\n",
    "# Drop\n",
    "train_labels.drop(droptable, inplace=True, axis=1)\n",
    "test_labels.drop(droptable, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33bc9bfb-29c9-47fd-a1f7-b99d1ef4a42a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "price_per_square_meter = train_targets/train['area_total'] # real price / real_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0c646bb-719b-46ca-bc9f-e97124ee5c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_advisor_1 = xgboost.XGBRegressor(max_depth=5, min_child_weight=12, gamma=0.15,\n",
    "                                 subsample=0.8, colsample_bytree=0.8, reg_alpha=1.1,\n",
    "                                 reg_lambda=0.3, learning_rate=0.01, n_estimators=10000)\n",
    "\n",
    "xgb_oof_train_1, xgb_oof_test_1, scores_1 = get_oof_xgboost(xgb_advisor_1, train_labels.drop(['area_total'],axis=1),\n",
    "                                                      np.log(price_per_square_meter), test_labels.drop(['area_total'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5dbffeab-49e2-4aac-9789-5560a4016e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20252494570910018, 0.1719402910622423, 0.19194384452156768, 0.18187339676857273, 0.23624429647388234]\n"
     ]
    }
   ],
   "source": [
    "print(scores_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a98c52b5-3ca1-4cda-9823-0b875a412c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"oofs/xgb_oof_train_area\", xgb_oof_train_1)\n",
    "np.savez(\"oofs/xgb_oof_test_area\", xgb_oof_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c2dc94-0090-44f4-a24d-6d87b9df6fcf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGB advisor 2 ðŸ˜Ž: Even more features - as well as area total - predicting price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c27b699d-0446-431a-8292-2116ba9e03c4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\School\\hÃ¸st 2021\\TDT4173-ML\\common_utils.py:1467: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  train_labels = train_labels.fillna(train_labels.median()) # Boolean\n",
      "C:\\School\\hÃ¸st 2021\\TDT4173-ML\\common_utils.py:1476: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  test_labels = test_labels.fillna(test_labels.median()) # Boolean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minMax\n"
     ]
    }
   ],
   "source": [
    "features =           [\"building_id\", # For grouping\n",
    "                      \"area_total\", \"area_kitchen\", \"area_living\", \"floor\", \"ceiling\", \"stories\", \"rooms\",\n",
    "                      \"bathrooms_private\", \"bathrooms_shared\", \"balconies\",\"loggias\", \"phones\", \"latitude\", \"longitude\", \"constructed\", # Numerical\n",
    "                     \"layout\", \"condition\", \"district\", \"material\", \"parking\", \"heating\", \"seller\", #Categorical\n",
    "                      \"windows_court\", \"windows_street\", \"new\", \"elevator_without\", \"elevator_passenger\", \"elevator_service\", \"garbage_chute\", # Bool\n",
    "                     \"street\"] #, \"address\"] # Strings\n",
    "\n",
    "all_numerical_features = [\"area_total\", \"area_kitchen\", \"area_living\", \"floor\",\n",
    "                      \"ceiling\", \"stories\", \"rooms\", \"bathrooms_private\", \"bathrooms_shared\", \"balconies\",\"loggias\", \"phones\", \"latitude\", \"longitude\", \"constructed\"]\n",
    "\n",
    "float_numerical_features = [\"area_total\", \"area_kitchen\", \"area_living\", \"ceiling\", \"latitude\", \"longitude\", \"constructed\"]\n",
    "int_numerical_features = [\"floor\", \"stories\", \"rooms\", \"bathrooms_private\", \"bathrooms_shared\", \"balconies\", \"loggias\", \"phones\"] # Ordinal categories\n",
    "\n",
    "cat_features = [\"layout\", \"condition\", \"district\", \"material\", \"parking\", \"heating\", \"seller\"] # All are non-ordinal\n",
    "\n",
    "droptable = [\"street\"]\n",
    "\n",
    "# Load data\n",
    "train, test, metaData = load_all_data()\n",
    "# Clean data. \n",
    "train_labels, train_targets, test_labels = clean_data(train, test, features, float_numerical_features, int_numerical_features, cat_features,\n",
    "                                                      log_targets=True, log_area=True, fillNan=True)\n",
    "# Add new features\n",
    "train_labels, test_labels, added_features = feature_engineering(train_labels, test_labels,\n",
    "    add_base_features=True, \n",
    "    add_bool_features=True,\n",
    "    add_weak_features=True,\n",
    "    add_dist_to_metro=True,\n",
    "    add_close_to_uni=True,\n",
    "    add_dist_to_hospital=True,\n",
    "    add_floor_features=True,\n",
    "    add_street_info=True,\n",
    "    add_some_more_features=True                                                            \n",
    "    )\n",
    "# Normalize\n",
    "train_labels, test_labels = normalize(train_labels, test_labels, float_numerical_features, scaler=\"minMax\")\n",
    "# Drop\n",
    "train_labels.drop(droptable, inplace=True, axis=1)\n",
    "test_labels.drop(droptable, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caa60c14-bc20-4e8e-8dc1-ea30e833c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_advisor_2 = xgboost.XGBRegressor(max_depth=5, min_child_weight=12, gamma=0.15,\n",
    "                                 subsample=0.8, colsample_bytree=0.8, reg_alpha=1.1,\n",
    "                                 reg_lambda=0.3, learning_rate=0.01, n_estimators=10000)\n",
    "\n",
    "xgb_oof_train_2, xgb_oof_test_2, scores_2 = get_oof_xgboost(xgb_advisor_2, train_labels,\n",
    "                                                      train_targets, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8833cab7-89a6-420b-811d-6bfbcc16c217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.21366608257200162, 0.17480404267524746, 0.19900553175201274, 0.18699747945287365, 0.2390275085244918]\n"
     ]
    }
   ],
   "source": [
    "print(scores_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "02771e7b-e8fe-46e8-9668-52d194ade66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"oofs/xgb_oof_train_price\", xgb_oof_train_2)\n",
    "np.savez(\"oofs/xgb_oof_test_price\", xgb_oof_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6346d3b7-652c-42d3-a058-ae8f6f05b0bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### DL advisor 1 - Predicting area_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4e3074a3-3530-41b4-8718-9d8ff75cd2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../common_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ece0e8f7-eb77-4219-9c23-63e168039fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostly the ones correlated to price.\n",
    "float_numerical_features = [\"area_total\", \"area_kitchen\", \"area_living\", \"latitude\", \"longitude\", \"ceiling\"]\n",
    "\n",
    "int_numerical_features = [\"floor\", \"stories\", \"rooms\", \"bathrooms_shared\", \"bathrooms_private\", \"balconies\", \"constructed\"]\n",
    "\n",
    "cat_features = [\"district\", \"material\", \"parking\", \"seller\"]\n",
    "\n",
    "bool_features = []\n",
    "\n",
    "features = [\"building_id\", \"street\"] + float_numerical_features + int_numerical_features + cat_features + bool_features\n",
    "\n",
    "# Many of the features was just added to help clean/engineer other features.\n",
    "droptable = ['longitude', 'latitude', 'area_kitchen', 'area_living', 'floor', 'stories', \"street\",\n",
    "            \"rel_living\", \"bathrooms_shared\", \"bathrooms_private\", \"theta\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ce195bf7-fced-465e-b2d1-ee02dc286141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train, test, metaData = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ac72fe8a-e1b0-426f-bd5b-8e852deb745b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\School\\hÃ¸st 2021\\TDT4173-ML\\common_utils.py:1508: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  train_labels = train_labels.fillna(train_labels.median()) # Boolean\n",
      "C:\\School\\hÃ¸st 2021\\TDT4173-ML\\common_utils.py:1517: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  test_labels = test_labels.fillna(test_labels.median()) # Boolean\n"
     ]
    }
   ],
   "source": [
    "# Clean data\n",
    "train_labels, train_targets, test_labels = clean_data(train, test, features, float_numerical_features, int_numerical_features, cat_features,\n",
    "                                                      log_targets=False, log_area=False, fillNan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1441cf27-0511-4793-a933-5d7b50455db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "train_labels, test_labels, added_features = feature_engineering(train_labels, test_labels,\n",
    "    add_base_features=True, \n",
    "    add_bool_features=False,\n",
    "    add_weak_features=False,\n",
    "    add_dist_to_metro=True,\n",
    "    add_close_to_uni=False,\n",
    "    add_dist_to_hospital=False,\n",
    "    add_floor_features=False,\n",
    "    add_street_info=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ea8c64d2-b760-4fc4-b3f3-3c371301d9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minMax\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "train_labels, test_labels = normalize(train_labels, test_labels, float_numerical_features, scaler=\"minMax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d2a51c0f-0afe-4e72-b608-d59da8e5f288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding\n",
    "train_labels, test_labels = one_hot_encoder(train_labels, test_labels,\n",
    "                                            cat_features, drop_old=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "564746d2-7a77-4f29-a86d-f5df36283883",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Droptable\n",
    "train_labels.drop(droptable, inplace=True, axis=1)\n",
    "test_labels.drop(droptable, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d9fdfc84-cd61-497b-bf4e-b87b2bc9dfab",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_per_square_meter = train_targets/train['area_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ec3279c2-3a0e-4ba1-b06b-0da89926689d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "..........Epoch 00510: early stopping\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "................................................Epoch 00948: early stopping\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      ".........................................................................................Epoch 00689: early stopping\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      ".Epoch 00701: early stopping\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      ".....................................................................Epoch 00669: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_params = ([18, 18, 18], tensorflow.nn.leaky_relu,\n",
    "                     [False, False, False], 0.2, 'adam',\n",
    "                      rmsle_custom, ['mse', 'msle', tensorflow.keras.metrics.Accuracy()], True)\n",
    "\n",
    "ann_oof_train_1, ann_oof_test_1, hists_1 = get_oof_ann(model_params,\n",
    "                                                 train_labels.drop(['area_total'],axis=1),\n",
    "                                                 price_per_square_meter,\n",
    "                                                 test_labels.drop(['area_total'],axis=1), strict_restart=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9a7ef89e-ea28-4353-b067-82610e77644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22691620886325836, 0.216660276055336, 0.21282845735549927, 0.21846720576286316, 0.24183255434036255, "
     ]
    }
   ],
   "source": [
    "for history in hists_1:\n",
    "    print(history.history[\"val_loss\"][-1], end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a7d5fd15-33a0-4475-a72b-5b29b111fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"oofs/ann_oof_train_area\", ann_oof_train_1)\n",
    "np.savez(\"oofs/ann_oof_test_area\", ann_oof_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e3fed1-2058-4e9b-8fc8-7d20250109a6",
   "metadata": {},
   "source": [
    "### DL advisor 2 - Predicting price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8e0ae994-5c91-4d82-84af-e23f6895dbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../common_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "fe8eaf89-8627-429e-8269-0fe176d71c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostly the ones correlated to price.\n",
    "float_numerical_features = [\"area_total\", \"area_kitchen\", \"area_living\", \"latitude\", \"longitude\", \"ceiling\"]\n",
    "\n",
    "int_numerical_features = [\"floor\", \"stories\", \"rooms\", \"bathrooms_shared\", \"bathrooms_private\", \"balconies\", \"constructed\"]\n",
    "\n",
    "cat_features = [\"district\", \"material\", \"parking\", \"seller\"]\n",
    "\n",
    "bool_features = []\n",
    "\n",
    "features = [\"building_id\", \"street\"] + float_numerical_features + int_numerical_features + cat_features + bool_features\n",
    "\n",
    "# Many of the features was just added to help clean/engineer other features.\n",
    "droptable = ['longitude', 'latitude', 'area_kitchen', 'area_living', 'floor', 'stories', \"street\",\n",
    "            \"rel_living\", \"bathrooms_shared\", \"bathrooms_private\", \"theta\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "abd1ca5e-1a41-4bdd-af73-b2d6e862fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train, test, metaData = load_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9479c2e3-06de-429e-9569-46c2ea7efae1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\School\\hÃ¸st 2021\\TDT4173-ML\\common_utils.py:1513: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  train_labels = train_labels.fillna(train_labels.median()) # Boolean\n",
      "C:\\School\\hÃ¸st 2021\\TDT4173-ML\\common_utils.py:1522: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  test_labels = test_labels.fillna(test_labels.median()) # Boolean\n"
     ]
    }
   ],
   "source": [
    "# Clean data\n",
    "train_labels, train_targets, test_labels = clean_data(train, test, features, float_numerical_features, int_numerical_features, cat_features,\n",
    "                                                      log_targets=False, log_area=False, fillNan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "50359ce7-dd31-4b2f-a2b5-0b52ed549450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "train_labels, test_labels, added_features = feature_engineering(train_labels, test_labels,\n",
    "    add_base_features=True, \n",
    "    add_bool_features=False,\n",
    "    add_weak_features=False,\n",
    "    add_dist_to_metro=True,\n",
    "    add_close_to_uni=False,\n",
    "    add_dist_to_hospital=False,\n",
    "    add_floor_features=False,\n",
    "    add_street_info=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3c280ccd-a921-4a73-882c-d5eac766bf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minMax\n"
     ]
    }
   ],
   "source": [
    "# Normalize\n",
    "train_labels, test_labels = normalize(train_labels, test_labels, float_numerical_features, scaler=\"minMax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "242ed24f-4aa1-4835-bfdd-76999f648088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droptable\n",
    "train_labels.drop(droptable, inplace=True, axis=1)\n",
    "test_labels.drop(droptable, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "166a4f24-846d-4544-835b-49a78c8dbfba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      ".......................................Epoch 00539: early stopping\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      ".......................................................Epoch 00655: early stopping\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "...............................................................................................Epoch 00695: early stopping\n",
      "\n",
      ".........................................Epoch 00041: early stopping\n",
      "Strict restart!\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "...................................................................................................."
     ]
    }
   ],
   "source": [
    "model_params = ([18, 18, 18], tensorflow.nn.leaky_relu,\n",
    "                     [False, False, False], 0.2, 'adam',\n",
    "                      rmsle_custom, ['mse', 'msle', tensorflow.keras.metrics.Accuracy()], True)\n",
    "\n",
    "ann_oof_train_2, ann_oof_test_2, hists_2 = get_oof_ann(model_params,\n",
    "                                                 train_labels,\n",
    "                                                 train_targets,\n",
    "                                                 test_labels, strict_restart=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e5908f67-e464-4191-a545-e242a18d8de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25357669591903687, 0.24738579988479614, 0.24683038890361786, 0.2576080560684204, 0.3004554212093353, "
     ]
    }
   ],
   "source": [
    "for history in hists_2:\n",
    "    print(history.history[\"val_loss\"][-1], end=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a3026922-086d-4f06-89ee-10f69d45f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"oofs/ann_oof_train_price\", ann_oof_train_2)\n",
    "np.savez(\"oofs/ann_oof_test_price\", ann_oof_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1feb2a-0c15-4a7a-a464-6b6a8c7f1a9a",
   "metadata": {},
   "source": [
    "### Best LGB advisor - predicts price/area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "28d11369-ab1a-482b-a4a9-c85740b8827a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\School\\hÃ¸st 2021\\TDT4173-ML\\common_utils.py:1513: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  train_labels = train_labels.fillna(train_labels.median()) # Boolean\n",
      "C:\\School\\hÃ¸st 2021\\TDT4173-ML\\common_utils.py:1522: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  test_labels = test_labels.fillna(test_labels.median()) # Boolean\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minMax\n"
     ]
    }
   ],
   "source": [
    "features =           [\"building_id\", # For grouping\n",
    "                      \"area_total\", \"area_kitchen\", \"area_living\", \"floor\", \"ceiling\", \"stories\", \"rooms\",\n",
    "                      \"bathrooms_private\", \"bathrooms_shared\", \"balconies\",\"loggias\", \"phones\", \"latitude\", \"longitude\", \"constructed\", # Numerical\n",
    "                     \"layout\", \"condition\", \"district\", \"material\", \"parking\", \"heating\", \"seller\", #Categorical\n",
    "                      \"windows_court\", \"windows_street\", \"new\", \"elevator_without\", \"elevator_passenger\", \"elevator_service\", \"garbage_chute\", # Bool\n",
    "                     \"street\", \"address\"] # Strings\n",
    "\n",
    "all_numerical_features = [\"area_total\", \"area_kitchen\", \"area_living\", \"floor\",\n",
    "                      \"ceiling\", \"stories\", \"rooms\", \"bathrooms_private\", \"bathrooms_shared\", \"balconies\",\"loggias\", \"phones\", \"latitude\", \"longitude\", \"constructed\"]\n",
    "\n",
    "float_numerical_features = [\"area_total\", \"area_kitchen\", \"area_living\", \"ceiling\", \"latitude\", \"longitude\", \"constructed\"]\n",
    "int_numerical_features = [\"floor\", \"stories\", \"rooms\", \"bathrooms_private\", \"bathrooms_shared\", \"balconies\", \"loggias\", \"phones\"] # Ordinal categories\n",
    "\n",
    "cat_features = [\"layout\", \"condition\", \"district\", \"material\", \"parking\", \"heating\", \"seller\"] # All are non-ordinal\n",
    "\n",
    "droptable = []\n",
    "\n",
    "# Load data\n",
    "train, test, metaData = load_all_data()\n",
    "# Clean data\n",
    "train_labels, train_targets, test_labels = clean_data(train, test, features, float_numerical_features, int_numerical_features, cat_features,\n",
    "                                                      log_targets=False, log_area=True, fillNan=True)\n",
    "# Add new features\n",
    "train_labels, test_labels, added_features = feature_engineering(\n",
    "    train_labels, \n",
    "    test_labels,\n",
    "    add_base_features=True, \n",
    "    add_bool_features=True,\n",
    "    add_weak_features=True,\n",
    "    add_dist_to_metro=True,\n",
    "    add_close_to_uni=True,\n",
    "    add_dist_to_hospital=True,\n",
    "    add_floor_features=True,\n",
    "    add_street_info=True,\n",
    "    add_some_more_features=True,\n",
    "    add_district_information=True,\n",
    "    )\n",
    "\n",
    "# Normalize\n",
    "train_labels, test_labels = normalize(train_labels, test_labels, float_numerical_features, scaler=\"minMax\")\n",
    "# One-hot encoding\n",
    "train_labels, test_labels = one_hot_encoder(train_labels, test_labels, [\"condition\", \"district\", \"material\", \"parking\", \"heating\", \"seller\"], drop_old=True)\n",
    "# Drop some features\n",
    "train_labels.drop(droptable, inplace=True, axis=1)\n",
    "test_labels.drop(droptable, inplace=True, axis=1)\n",
    "\n",
    "droptable = ['street','address']\n",
    "train_labels.drop(droptable, inplace=True, axis=1)\n",
    "test_labels.drop(droptable, inplace=True, axis=1)\n",
    "\n",
    "# Price per area\n",
    "price_per_square_meter = train_targets/train['area_total'] # real price / real_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2c539128-e4c3-4986-a158-d2f6e7714307",
   "metadata": {},
   "outputs": [],
   "source": [
    "params= {\n",
    " 'num_iterations': 10000,\n",
    " 'n_estimators': 152*5,\n",
    " 'learning_rate': 0.05/5,\n",
    " 'num_leaves': 40,\n",
    " 'max_depth': 10,\n",
    " 'min_data_in_leaf': 20,\n",
    " 'bagging_fraction': 0.9,\n",
    " 'bagging_freq': 5,\n",
    " 'feature_fraction': 0.8,\n",
    "}\n",
    "\n",
    "lgbm_model = lightgbm.LGBMRegressor(\n",
    "    **params, \n",
    "    random_state=42,\n",
    "    early_stopping_round=100,\n",
    "    silent=True,\n",
    "    metric='regression',\n",
    "    num_threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "81947ffc-7963-47d4-a8e8-952940b06f9e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python38\\lib\\site-packages\\lightgbm\\sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\python\\python38\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "c:\\python\\python38\\lib\\site-packages\\lightgbm\\engine.py:177: UserWarning: Found `num_iterations` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] num_threads is set=4, n_jobs=-1 will be ignored. Current value: num_threads=4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[998]\tvalid_0's l2: 0.0395304\tvalid_0's custom_asymmetric_eval: 0.0146689\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] num_threads is set=4, n_jobs=-1 will be ignored. Current value: num_threads=4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[785]\tvalid_0's l2: 0.0300391\tvalid_0's custom_asymmetric_eval: 0.0128922\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] num_threads is set=4, n_jobs=-1 will be ignored. Current value: num_threads=4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1050]\tvalid_0's l2: 0.0369381\tvalid_0's custom_asymmetric_eval: 0.0142402\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] num_threads is set=4, n_jobs=-1 will be ignored. Current value: num_threads=4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[970]\tvalid_0's l2: 0.0351368\tvalid_0's custom_asymmetric_eval: 0.0137883\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8\n",
      "[LightGBM] [Warning] min_data_in_leaf is set=20, min_child_samples=20 will be ignored. Current value: min_data_in_leaf=20\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9\n",
      "[LightGBM] [Warning] num_threads is set=4, n_jobs=-1 will be ignored. Current value: num_threads=4\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[560]\tvalid_0's l2: 0.0482705\tvalid_0's custom_asymmetric_eval: 0.0161712\n"
     ]
    }
   ],
   "source": [
    "lgbm_oof_train, lgbm_oof_test, scores = get_oof_lgbm(lgbm_model,\n",
    "                                                     train_labels.drop(['area_total'],axis=1),\n",
    "                                                     np.log(price_per_square_meter),\n",
    "                                                     test_labels.drop(['area_total'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4e63ac4d-b738-43ea-9fc3-cf7f428259f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.19882169591944485, 0.17331712016749312, 0.1921920843857648, 0.18744743537675287, 0.21970472822532938]\n"
     ]
    }
   ],
   "source": [
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0a892023-f7d5-48d5-8094-ebb17d334f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(\"oofs/lgb_oof_train_area\", lgbm_oof_train)\n",
    "np.savez(\"oofs/lgb_oof_test_area\", lgbm_oof_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daa6900-1260-430d-a02d-55a95d09497f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGBoost King"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7812d6b2-035a-4d53-9f73-2aa384e34a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train[[\"building_id\", \"area_total\"]]\n",
    "test_labels = test[[\"building_id\", \"area_total\"]]\n",
    "train_targets = train['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fc14215a-10ad-4199-8e05-6b46a2a487cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD\n",
    "old_lgbm_oof_train = np.load(\"oofs/old_lgbm_oof_train.npz\")['arr_0'] \n",
    "old_lgbm_oof_test = np.load(\"oofs/old_lgbm_oof_test.npz\")['arr_0'] \n",
    "\n",
    "old_rf_oof_train = np.load(\"oofs/old_rf_oof_train.npz\")['arr_0'] \n",
    "old_rf_oof_test = np.load(\"oofs/old_rf_oof_test.npz\")['arr_0'] \n",
    "\n",
    "old_xgb_oof_train = np.load(\"oofs/old_xgb_oof_train.npz\")['arr_0'] \n",
    "old_xgb_oof_test = np.load(\"oofs/old_xgb_oof_test.npz\")['arr_0'] \n",
    "\n",
    "old_ann_oof_train = np.load(\"oofs/old_ann_oof_train.npz\")['arr_0'] \n",
    "old_ann_oof_test = np.load(\"oofs/old_ann_oof_test.npz\")['arr_0'] \n",
    "# NEW\n",
    "lgbm_oof_train_area = np.load(\"oofs/lgb_oof_train_area.npz\")['arr_0'] \n",
    "lgbm_oof_test_area = np.load(\"oofs/lgb_oof_test_area.npz\")['arr_0']\n",
    "\n",
    "ann_oof_train_area = np.load(\"oofs/ann_oof_train_area.npz\")['arr_0'] \n",
    "ann_oof_test_area = np.load(\"oofs/ann_oof_test_area.npz\")['arr_0']\n",
    "\n",
    "ann_oof_train_price = np.load(\"oofs/ann_oof_train_price.npz\")['arr_0'] \n",
    "ann_oof_test_price = np.load(\"oofs/ann_oof_test_price.npz\")['arr_0']\n",
    "\n",
    "xgb_oof_train_area = np.load(\"oofs/xgb_oof_train_area.npz\")['arr_0'] \n",
    "xgb_oof_test_area = np.load(\"oofs/xgb_oof_test_area.npz\")['arr_0']\n",
    "\n",
    "xgb_oof_train_price = np.load(\"oofs/xgb_oof_train_price.npz\")['arr_0'] \n",
    "xgb_oof_test_price = np.load(\"oofs/xgb_oof_test_price.npz\")['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3e783fbc-131e-4ccb-8310-c63abc69f2a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4040/1335917435.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# The old advisors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"old_xgb_preds\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_xgb_oof_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'area_total'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"old_xgb_preds\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_xgb_oof_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'area_total'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"old_lgbm_preds\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_lgbm_oof_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'area_total'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2030\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2031\u001b[0m     ):\n\u001b[1;32m-> 2032\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0marraylike\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_ufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2034\u001b[0m     \u001b[1;31m# ideally we would define this to avoid the getattr checks, but\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python38\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36marray_ufunc\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \u001b[1;31m# for binary ops, use our custom dunder methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_dispatch_ufunc_to_dunder_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python38\\lib\\site-packages\\pandas\\_libs\\ops_dispatch.pyx\u001b[0m in \u001b[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python38\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python38\\lib\\site-packages\\pandas\\core\\arraylike.py\u001b[0m in \u001b[0;36m__rtruediv__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__rtruediv__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__rtruediv__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_arith_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroperator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrtruediv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0munpack_zerodim_and_defer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"__floordiv__\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python38\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   5526\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5528\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5530\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python38\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_construct_result\u001b[1;34m(self, result, name)\u001b[0m\n\u001b[0;32m   2943\u001b[0m         \u001b[1;31m# We do not pass dtype to ensure that the Series constructor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2944\u001b[0m         \u001b[1;31m#  does inference in the case where `result` has object-dtype.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2945\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2947\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python38\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    437\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[0mmanager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_option\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"mode.data_manager\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python38\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[0;32m    574\u001b[0m                 \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 576\u001b[1;33m     \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_sanitize_ndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_2d\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python38\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36m_sanitize_ndim\u001b[1;34m(result, data, dtype, index, allow_2d)\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExtensionDtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m             \u001b[1;31m# i.e. PandasDtype(\"O\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "# The old advisors\n",
    "train_labels[\"old_xgb_preds\"] = np.log(np.exp(old_xgb_oof_train) / train['area_total'])\n",
    "test_labels[\"old_xgb_preds\"] = np.log(np.exp(old_xgb_oof_test) / test['area_total'])\n",
    "\n",
    "train_labels[\"old_lgbm_preds\"] = np.log(np.exp(old_lgbm_oof_train) / train['area_total'])\n",
    "test_labels[\"old_lgbm_preds\"] = np.log(np.exp(old_lgbm_oof_test) / test['area_total'])\n",
    "\n",
    "train_labels[\"old_ann_preds\"] = np.log(old_ann_oof_train / train['area_total'])\n",
    "test_labels[\"old_ann_preds\"] = np.log(old_ann_oof_test / test['area_total'])\n",
    "\n",
    "train_labels[\"old_rf_preds\"] = np.log(old_rf_oof_train / train['area_total'])\n",
    "test_labels[\"old_rf_preds\"] = np.log(old_rf_oof_test / test['area_total'])\n",
    "\n",
    "# New advisor\n",
    "train_labels[\"lgbm_oof_train_area\"] = lgbm_oof_train_area\n",
    "test_labels[\"lgbm_oof_test_area\"] = lgbm_oof_test_area\n",
    "\n",
    "train_labels[\"ann_oof_train_area\"] = np.log(ann_oof_train_area)\n",
    "test_labels[\"ann_oof_test_area\"] = np.log(ann_oof_test_area)\n",
    "\n",
    "train_labels[\"ann_oof_train_price\"] = np.log(ann_oof_train_price / test['area_total'])\n",
    "test_labels[\"ann_oof_test_price\"] = np.log(ann_oof_test_price / test['area_total'])\n",
    "\n",
    "train_labels[\"xgb_oof_train_area\"] = xgb_oof_train_area\n",
    "test_labels[\"xgb_oof_test_area\"] = xgb_oof_test_area\n",
    "\n",
    "train_labels[\"xgb_oof_train_price\"] = np.log(np.exp(xgb_oof_train_price) / train['area_total'])\n",
    "test_labels[\"xgb_oof_test_price\"] = np.log(np.exp(xgb_oof_test_price) / test['area_total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cb14b1-231b-42f5-b1b6-0f83d9bbe6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_per_square_meter = train_targets/train['area_total'] # real price / real_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837f2ef5-ef09-4283-854a-31af9a535a89",
   "metadata": {},
   "source": [
    "### Stacking the standard way. TODO - normalize the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f15f9-9ac2-4d42-874d-5604830f97e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = [5, 12, 0.15, 0.8, 0.8, 1.1, 0.3, 0.01, 10000]\n",
    "scores, avg, best_model, models = XGB_groupKFold(5, model_params,\n",
    "                                                 train_labels.drop(['area_total'],axis=1), np.log(price_per_square_meter),\n",
    "                                                 eval_metric='rmse')\n",
    "print(scores)\n",
    "print(\"=>\",avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2100a5ce-6ea8-4adc-955c-0a3a972e9c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_store(best_model, test_labels.drop([\"building_id\", \"area_total\"], axis=1),\n",
    "                  test, path=\"ensemble_predictions/stacking_on_old_and_new_1\", exponential=True,\n",
    "                  price_per_sq=True, total_area_df=test[\"area_total\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445ad12a-2006-4de5-8c2e-d4e6c26b2b35",
   "metadata": {},
   "source": [
    "#### Now train on all the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a485e6f-ec92-4273-bbac-1d8152dc262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a model, predicting on all the stuff. Might overfit a lot!\n",
    "xgb_model = xgboost.XGBRegressor(max_depth=5, min_child_weight=12, gamma=0.15, subsample=0.8, colsample_bytree=0.8, reg_alpha=1.1, reg_lambda=0.3, learning_rate=0.01, n_estimators=10000)\n",
    "fit_data = xgb_model.fit(train_labels.drop(['area_total', 'building_id'],axis=1),\n",
    "            np.log(price_per_square_meter),\n",
    "            eval_metric='rmse',\n",
    "            verbose=False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985e3a94-a49b-4cd9-987d-ad5018ddb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training score\n",
    "prediction = np.exp(xgb_model.predict(train_labels.drop(['area_total', 'building_id'],axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb811b8-8291-4386-b2b6-d8ec47127537",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_store(xgb_model, test_labels.drop([\"building_id\", \"area_total\"], axis=1),\n",
    "                  test, path=\"ensemble_predictions/stacking_on_all_data_1\", exponential=True,\n",
    "                  price_per_sq=True, total_area_df=test[\"area_total\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
