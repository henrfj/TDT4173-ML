{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - K-fold validation\n",
    "#### Sources\n",
    "- https://www.machinecurve.com/index.php/2020/02/18/how-to-use-k-fold-cross-validation-with-keras/\n",
    "- https://medium.com/the-owl/k-fold-cross-validation-in-keras-3ec4a3a00538\n",
    "\n",
    "A method to validate model more accurately than just using one set of validation data.\n",
    "Also: stacking the k-fold models could lead to better accuracy, as the result is a model that has seen and trained on all the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Simple average stacking\n",
    "Use the average of the predictions over the models, instead of using just one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Specific tf libraries\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../common_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tls = []\n",
    "tts = []\n",
    "vls = []\n",
    "vts = []\n",
    "tstl = []\n",
    "train, test, metaData = load_all_data()\n",
    "\n",
    "\n",
    "# Features 1 \"All features\"\n",
    "features =           [\"area_total\", \"area_kitchen\", \"area_living\", \"floor\", \"ceiling\", \"stories\", \"rooms\", \"bathrooms_private\", \"bathrooms_shared\", \"balconies\",\"loggias\", \"phones\", \"latitude\", \"longitude\", \"constructed\", # Numerical\n",
    "                     \"layout\", \"condition\", \"district\", \"material\", \"parking\", \"heating\", #Categorical\n",
    "                      \"windows_court\", \"windows_street\", \"new\", \"elevator_without\", \"elevator_passenger\", \"elevator_service\", \"garbage_chute\"] # Bool\n",
    "                     #\"street\", \"address\"] #String\n",
    "\n",
    "numerical_features = [\"area_total\", \"area_kitchen\", \"area_living\",\n",
    "                      \"floor\", \"stories\", \"rooms\", \"bathrooms_shared\", \"balconies\", \"latitude\", \"longitude\", \"constructed\", \"r\", \"rel_height\"]\n",
    "\n",
    "cat_features = [\"layout\", \"condition\", \"district\", \"material\", \"parking\", \"heating\"]\n",
    "\n",
    "droptable = ['longitude', 'latitude', 'floor', 'stories'] # Not dropping theta!\n",
    "\n",
    "train_labels, train_targets, val_labels, val_targets, test_labels = pre_process_numerical(\n",
    "        features, numerical_features, train, test, outliers_value=7, val_split=0.1, random_state=42, scaler=\"std\",\n",
    "        add_R=\"True\", add_rel_height=\"True\", droptable=droptable,\n",
    "        one_hot_encode=True, cat_features=cat_features, drop_old=True)\n",
    "\n",
    "tls.append(train_labels)\n",
    "tts.append(train_targets)\n",
    "vls.append(val_labels)\n",
    "vts.append(val_targets)\n",
    "tstl.append(test_labels)\n",
    "\n",
    "# Features 2 \"best features\"\n",
    "features =           [\"area_total\", \"area_kitchen\", \"area_living\", \"floor\", \"stories\", \"rooms\", \"bathrooms_shared\", \"balconies\", \"latitude\", \"longitude\", \"constructed\", # Numerical\n",
    "                    \"district\", \"material\", \"parking\"] \n",
    "\n",
    "numerical_features = [\"area_total\", \"area_kitchen\", \"area_living\",\n",
    "                      \"floor\", \"stories\", \"rooms\", \"bathrooms_shared\", \"balconies\", \"latitude\", \"longitude\", \"constructed\", \"r\", \"rel_height\"]\n",
    "\n",
    "cat_features = [\"district\", \"material\", \"parking\"]\n",
    "\n",
    "droptable = ['longitude', 'latitude', 'area_kitchen', 'area_living', 'floor', 'stories'] # Not dropping theta!\n",
    "\n",
    "# Data pre-processing\n",
    "train_labels, train_targets, val_labels, val_targets, test_labels = pre_process_numerical(\n",
    "        features, numerical_features, train, test, outliers_value=7, val_split=0.1, random_state=42, scaler=\"minMax\",\n",
    "        add_R=\"True\", add_rel_height=\"True\", droptable=droptable,\n",
    "        one_hot_encode=False, cat_features=cat_features, drop_old=False)\n",
    "\n",
    "tls.append(train_labels)\n",
    "tts.append(train_targets)\n",
    "vls.append(val_labels)\n",
    "vts.append(val_targets)\n",
    "tstl.append(test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "...........................................Epoch 01643: early stopping\n",
      "INFO:tensorflow:Assets written to: models/some_model_0\\assets\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      ".........................................................................Epoch 02373: early stopping\n",
      "INFO:tensorflow:Assets written to: models/some_model_1\\assets\n"
     ]
    }
   ],
   "source": [
    "# Creater 5 different models to stack\n",
    "# https://www.tensorflow.org/guide/keras/save_and_serialize#registering_the_custom_object\n",
    "\n",
    "model1 = create_ANN_model()\n",
    "model2 = create_ANN_model()\n",
    "#model3 = create_ANN_model()\n",
    "#model4 = create_ANN_model()\n",
    "#model5 = create_ANN_model()\n",
    "models = [model1, model2] #, model3, model4, model5]\n",
    "\n",
    "losses = []\n",
    "epochs = [10000, 10000, 1000, 1000, 2000]\n",
    "for i, model in enumerate(models):\n",
    "    train_labels = tls[i]\n",
    "    train_targets = tts[i]\n",
    "    val_labels = vls[i]\n",
    "    val_targets = vts[i]\n",
    "    test_labels = tstl[i]\n",
    "    e = epochs[i]\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, mode='min', patience=40)\n",
    "    history = model.fit(x=train_labels, y=train_targets.values,\n",
    "              validation_data=(val_labels,val_targets.values),\n",
    "              verbose=0, epochs=e, callbacks=[early_stop, PrintDot()]\n",
    "              )\n",
    "    \n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "    losses.append(hist['val_loss'].tail(1))\n",
    "    model.save('models/some_model_'+str(i))\n",
    "    predict_and_store(model, test_labels, test, path='advanced_tests/stacking_'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1642    0.200561\n",
      "Name: val_loss, dtype: float64, 2372    0.239887\n",
      "Name: val_loss, dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "print(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "...................................................................................................."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
