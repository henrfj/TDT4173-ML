{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4cc5865-92c4-433f-b550-99091a4db87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../common_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ed6f4da-ed00-491d-85bb-13cd45d44f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0a45627-3d89-4bc8-88d1-b279d5273995",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1\n",
    "number_of_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c295ed0e-7d3b-40e8-a1ad-4ec9646a6d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hot encoding\n",
      "Std\n"
     ]
    }
   ],
   "source": [
    "def load_data(val_data, one_hot):\n",
    "    train, test, metadata = load_all_data()\n",
    "    nonCategorical, categorical = get_cat_and_non_cat_data(metadata)\n",
    "#     categorical.remove('district')\n",
    "    all_features = list(train.columns)\n",
    "    all_features.remove('price')\n",
    "    numerical_features = ['area_total','area_kitchen','area_living','floor','rooms','ceiling',\n",
    "        'bathrooms_shared','bathrooms_private','balconies','loggias','phones','building_id','constructed','stories']\n",
    "    categorical_to_numerical(train, ['street','address'])\n",
    "    categorical_to_numerical(test, ['street','address'])\n",
    "    if not val_data:\n",
    "        X_train, y_train, test_labels = pre_process_numerical(\n",
    "                            features = all_features, numerical_features = numerical_features, train = train, test = test,\n",
    "                            outliers_value=7, val_data=val_data, val_split=0.2, random_state=42, scaler=\"std\",\n",
    "                            add_R=\"True\", add_rel_height=\"True\", droptable=[],\n",
    "                            one_hot_encode=one_hot, cat_features=categorical, drop_old=True)\n",
    "        y_train_log = np.log(y_train)\n",
    "        return X_train, y_train, y_train_log, test_labels\n",
    "    else:\n",
    "        X_train, y_train, X_test, y_test, test_labels = pre_process_numerical(features = all_features, numerical_features = numerical_features, train = train, test = test,\n",
    "                            outliers_value=7, val_data=val_data, val_split=0.2, random_state=42, scaler=\"std\",\n",
    "                            add_R=\"True\", add_rel_height=\"True\", droptable=[],\n",
    "                            one_hot_encode=one_hot, cat_features=categorical, drop_old=True)\n",
    "        y_train_log = np.log(y_train)\n",
    "        return X_train, y_train, y_train_log, X_test, y_test, test_labels\n",
    "\n",
    "X_train, y_train, y_train_log, test_labels = load_data(val_data=False, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b3354df-5761-42dd-b6bc-2eddb9ae55ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_n_estimators = 300\n",
    "optimal_max_depth = 13\n",
    "optimal_min_samples_split = 1000\n",
    "optimal_min_samples_leaf = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4a034bd-58f7-43b4-8c9e-326c70bef359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       -----------------       \n",
      "current min samples leaf:          30\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20789263957747525\n",
      "       -----------------       \n",
      "current min samples leaf:          40\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20446437151272606\n",
      "       -----------------       \n",
      "current min samples leaf:          50\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20512934983368442\n",
      "       -----------------       \n",
      "current min samples leaf:          60\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20500472689475532\n",
      "       -----------------       \n",
      "current min samples leaf:          70\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.2059830635130378\n"
     ]
    }
   ],
   "source": [
    "min_samples_leaf = np.arange(30,80,10).astype(int)\n",
    "\n",
    "best_average_score = 0.202723888466623\n",
    "\n",
    "for m_s_leaf in min_samples_leaf:\n",
    "    print(\"       -----------------       \")\n",
    "    print(\"current min samples leaf:         \", m_s_leaf)\n",
    "    params = dict(\n",
    "        min_samples_leaf = m_s_leaf,\n",
    "    )\n",
    "    model = GradientBoostingRegressor(\n",
    "                **params,\n",
    "                n_estimators = optimal_n_estimators,\n",
    "                max_depth = optimal_max_depth,\n",
    "                min_samples_split = optimal_min_samples_split,\n",
    "                learning_rate = 0.1,\n",
    "                loss = 'squared_error',\n",
    "                criterion = 'squared_error',\n",
    "                verbose = 0,\n",
    "                warm_start = False,\n",
    "            )\n",
    "    scores, average_score, _, _ = gradient_boost_groupKFold(number_of_splits=number_of_splits,\n",
    "                                                            model=model,\n",
    "                                                            X_train=X_train, \n",
    "                                                            y_train=y_train_log\n",
    "                                                            )\n",
    "    print(average_score)\n",
    "    if average_score < best_average_score:\n",
    "        best_average_score = average_score\n",
    "        best_params = params\n",
    "        print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "        print(\"scores: \", scores)\n",
    "        print(\"average score: \", average_score)\n",
    "        print(\"parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86acf7c3-fc1d-40f8-b795-7c5053b90093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       -----------------       \n",
      "current min samples leaf:          35\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.2085357274952901\n",
      "       -----------------       \n",
      "current min samples leaf:          37\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20563162445018673\n",
      "       -----------------       \n",
      "current min samples leaf:          39\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.207405732920709\n",
      "       -----------------       \n",
      "current min samples leaf:          41\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20443208560777598\n",
      "       -----------------       \n",
      "current min samples leaf:          43\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.2045631441792019\n"
     ]
    }
   ],
   "source": [
    "min_samples_leaf = np.arange(35,45,2).astype(int)\n",
    "\n",
    "best_average_score = 0.202723888466623\n",
    "\n",
    "for m_s_leaf in min_samples_leaf:\n",
    "    print(\"       -----------------       \")\n",
    "    print(\"current min samples leaf:         \", m_s_leaf)\n",
    "    params = dict(\n",
    "        min_samples_leaf = m_s_leaf,\n",
    "    )\n",
    "    model = GradientBoostingRegressor(\n",
    "                **params,\n",
    "                n_estimators = optimal_n_estimators,\n",
    "                max_depth = optimal_max_depth,\n",
    "                min_samples_split = optimal_min_samples_split,\n",
    "                learning_rate = 0.1,\n",
    "                loss = 'squared_error',\n",
    "                criterion = 'squared_error',\n",
    "                verbose = 0,\n",
    "                warm_start = False,\n",
    "            )\n",
    "    scores, average_score, _, _ = gradient_boost_groupKFold(number_of_splits=number_of_splits,\n",
    "                                                            model=model,\n",
    "                                                            X_train=X_train, \n",
    "                                                            y_train=y_train_log\n",
    "                                                            )\n",
    "    print(average_score)\n",
    "    if average_score < best_average_score:\n",
    "        best_average_score = average_score\n",
    "        best_params = params\n",
    "        print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "        print(\"scores: \", scores)\n",
    "        print(\"average score: \", average_score)\n",
    "        print(\"parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0959b833-76af-4ef2-9d7c-40a6de71f645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       -----------------       \n",
      "current max features:          30\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.2074228449462633\n",
      "       -----------------       \n",
      "current max features:          40\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20342692378142774\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "scores:  [0.2014331086123337, 0.1988135890993125, 0.1774051331351435, 0.20075602098785922, 0.2387267670724897]\n",
      "average score:  0.20342692378142774\n",
      "parameters:  {'max_features': 40}\n",
      "       -----------------       \n",
      "current max features:          50\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20400378726177318\n",
      "       -----------------       \n",
      "current max features:          60\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20628811961097232\n",
      "       -----------------       \n",
      "current max features:          70\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20437696226374918\n"
     ]
    }
   ],
   "source": [
    "max_features = np.arange(30,80,10).astype(int)\n",
    "\n",
    "best_average_score = 0.20446437151272606\n",
    "\n",
    "for m_feature in max_features:\n",
    "    print(\"       -----------------       \")\n",
    "    print(\"current max features:         \", m_feature)\n",
    "    params = dict(\n",
    "        max_features = m_feature,\n",
    "    )\n",
    "    model = GradientBoostingRegressor(\n",
    "                **params,\n",
    "                n_estimators = optimal_n_estimators,\n",
    "                max_depth = optimal_max_depth,\n",
    "                min_samples_split = optimal_min_samples_split,\n",
    "                min_samples_leaf = optimal_min_samples_leaf,\n",
    "                learning_rate = 0.1,\n",
    "                loss = 'squared_error',\n",
    "                criterion = 'squared_error',\n",
    "                verbose = 0,\n",
    "                warm_start = False,\n",
    "                random_state = random_state,\n",
    "            )\n",
    "    scores, average_score, _, _ = gradient_boost_groupKFold(number_of_splits=number_of_splits,\n",
    "                                                            model=model,\n",
    "                                                            X_train=X_train, \n",
    "                                                            y_train=y_train_log\n",
    "                                                            )\n",
    "    print(average_score)\n",
    "    if average_score < best_average_score:\n",
    "        best_average_score = average_score\n",
    "        best_params = params\n",
    "        print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "        print(\"scores: \", scores)\n",
    "        print(\"average score: \", average_score)\n",
    "        print(\"parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df1169f7-9139-4de5-82bf-f9af5ec4682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_max_features = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "136d139f-29e1-4491-ad43-318bf77319ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       -----------------       \n",
      "current subsample:          0.65\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.21134666306966693\n",
      "       -----------------       \n",
      "current subsample:          0.7000000000000001\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20913886387701205\n",
      "       -----------------       \n",
      "current subsample:          0.7500000000000001\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20890309954138098\n",
      "       -----------------       \n",
      "current subsample:          0.8000000000000002\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20745419817834435\n",
      "       -----------------       \n",
      "current subsample:          0.8500000000000002\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20815033148423306\n",
      "       -----------------       \n",
      "current subsample:          0.9000000000000002\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20696062743075724\n",
      "       -----------------       \n",
      "current subsample:          0.9500000000000003\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.2070132291467654\n"
     ]
    }
   ],
   "source": [
    "subsample = np.arange(0.65,1,0.05).astype(float)\n",
    "\n",
    "best_average_score = 0.20342692378142774\n",
    "\n",
    "for subs in subsample:\n",
    "    print(\"       -----------------       \")\n",
    "    print(\"current subsample:         \", subs)\n",
    "    params = dict(\n",
    "        subsample = subs,\n",
    "    )\n",
    "    model = GradientBoostingRegressor(\n",
    "                **params,\n",
    "                n_estimators = optimal_n_estimators,\n",
    "                max_depth = optimal_max_depth,\n",
    "                min_samples_split = optimal_min_samples_split,\n",
    "                min_samples_leaf = optimal_min_samples_leaf,\n",
    "                max_features = optimal_max_features,\n",
    "                learning_rate = 0.1,\n",
    "                loss = 'squared_error',\n",
    "                criterion = 'squared_error',\n",
    "                verbose = 0,\n",
    "                warm_start = False,\n",
    "                random_state = random_state,\n",
    "            )\n",
    "    scores, average_score, _, _ = gradient_boost_groupKFold(number_of_splits=number_of_splits,\n",
    "                                                            model=model,\n",
    "                                                            X_train=X_train, \n",
    "                                                            y_train=y_train_log\n",
    "                                                            )\n",
    "    print(average_score)\n",
    "    if average_score < best_average_score:\n",
    "        best_average_score = average_score\n",
    "        best_params = params\n",
    "        print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "        print(\"scores: \", scores)\n",
    "        print(\"average score: \", average_score)\n",
    "        print(\"parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cbf2527-14b2-4d7e-b654-b34dc801c354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       -----------------       \n",
      "current subsample:          0.955\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20577203095223834\n",
      "       -----------------       \n",
      "current subsample:          0.96\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20642677371221801\n",
      "       -----------------       \n",
      "current subsample:          0.965\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20487331726378036\n",
      "       -----------------       \n",
      "current subsample:          0.97\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.2072606168415919\n",
      "       -----------------       \n",
      "current subsample:          0.975\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20664080750814814\n",
      "       -----------------       \n",
      "current subsample:          0.98\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20403579335780586\n",
      "       -----------------       \n",
      "current subsample:          0.985\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.2075514880168709\n",
      "       -----------------       \n",
      "current subsample:          0.99\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20512053285926402\n",
      "       -----------------       \n",
      "current subsample:          0.995\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20785204743870578\n",
      "       -----------------       \n",
      "current subsample:          1.0\n",
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20342692378142774\n",
      "       -----------------       \n",
      "current subsample:          1.005\n",
      "starting on split  1  of cross validation\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "subsample must be in (0,1] but was 1.005",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-41fc669d2da9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             )\n\u001b[1;32m---> 25\u001b[1;33m     scores, average_score, _, _ = gradient_boost_groupKFold(number_of_splits=number_of_splits,\n\u001b[0m\u001b[0;32m     26\u001b[0m                                                             \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                                                             \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ntnuProjects\\TDT4173-ML\\common_utils.py\u001b[0m in \u001b[0;36mgradient_boost_groupKFold\u001b[1;34m(number_of_splits, model, X_train, y_train)\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[0mX_train2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[0my_train2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m         model.fit(\n\u001b[0m\u001b[0;32m    301\u001b[0m             \u001b[0mX_train2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[0my_train2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[0mX_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m_check_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubsample\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 317\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"subsample must be in (0,1] but was %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubsample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: subsample must be in (0,1] but was 1.005"
     ]
    }
   ],
   "source": [
    "subsample = np.arange(0.955,1.01,0.005).astype(float)\n",
    "\n",
    "best_average_score = 0.20342692378142774\n",
    "\n",
    "for subs in subsample:\n",
    "    print(\"       -----------------       \")\n",
    "    print(\"current subsample:         \", subs)\n",
    "    params = dict(\n",
    "        subsample = subs,\n",
    "    )\n",
    "    model = GradientBoostingRegressor(\n",
    "                **params,\n",
    "                n_estimators = optimal_n_estimators,\n",
    "                max_depth = optimal_max_depth,\n",
    "                min_samples_split = optimal_min_samples_split,\n",
    "                min_samples_leaf = optimal_min_samples_leaf,\n",
    "                max_features = optimal_max_features,\n",
    "                learning_rate = 0.1,\n",
    "                loss = 'squared_error',\n",
    "                criterion = 'squared_error',\n",
    "                verbose = 0,\n",
    "                warm_start = False,\n",
    "                random_state = random_state,\n",
    "            )\n",
    "    scores, average_score, _, _ = gradient_boost_groupKFold(number_of_splits=number_of_splits,\n",
    "                                                            model=model,\n",
    "                                                            X_train=X_train, \n",
    "                                                            y_train=y_train_log\n",
    "                                                            )\n",
    "    print(average_score)\n",
    "    if average_score < best_average_score:\n",
    "        best_average_score = average_score\n",
    "        best_params = params\n",
    "        print(\">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>><<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "        print(\"scores: \", scores)\n",
    "        print(\"average score: \", average_score)\n",
    "        print(\"parameters: \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40ba319d-f34a-4172-a8e6-a89c3790b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_subsample = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48475d54-804a-4744-a866-6e236209652e",
   "metadata": {},
   "source": [
    "## Resulting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49a7adee-2d30-4101-b443-81b0adfbd356",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(\n",
    "            n_estimators = optimal_n_estimators,\n",
    "            max_depth = optimal_max_depth,\n",
    "            min_samples_split = optimal_min_samples_split,\n",
    "            min_samples_leaf = optimal_min_samples_leaf,\n",
    "            max_features = optimal_max_features,\n",
    "            subsample = optimal_subsample,\n",
    "            learning_rate = 0.1,\n",
    "            loss = 'squared_error',\n",
    "            criterion = 'squared_error',\n",
    "            verbose = 0,\n",
    "            warm_start = False,\n",
    "            random_state = random_state,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e0538d3-3daf-4e60-9c2a-d598214eaeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "0.20342692378142774\n"
     ]
    }
   ],
   "source": [
    "scores, average_score, _, _ = gradient_boost_groupKFold(number_of_splits=number_of_splits,\n",
    "                                                        model=model,\n",
    "                                                        X_train=X_train, \n",
    "                                                        y_train=y_train_log\n",
    "                                                        )\n",
    "print(\"Average score\", average_score)\n",
    "# This should be 0.203... OKAY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c0e5e-37a1-4593-b501-b10a23605016",
   "metadata": {},
   "source": [
    "## Decrease learning rate and increase number of trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "911d1b9c-9ab4-4677-a23d-108ce50bf60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9750704f-17f4-4cb5-b1b7-9d13235a5e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(\n",
    "            n_estimators = optimal_n_estimators*2,\n",
    "            max_depth = optimal_max_depth,\n",
    "            min_samples_split = optimal_min_samples_split,\n",
    "            min_samples_leaf = optimal_min_samples_leaf,\n",
    "            max_features = optimal_max_features,\n",
    "            subsample = optimal_subsample,\n",
    "            learning_rate = original_learning_rate / 2,\n",
    "            loss = 'squared_error',\n",
    "            criterion = 'squared_error',\n",
    "            verbose = 0,\n",
    "            warm_start = False,\n",
    "            random_state = random_state,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2fdd9360-c5f6-48d0-bfd5-8c4f548d239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "Average score 0.20310354997566646\n"
     ]
    }
   ],
   "source": [
    "scores, average_score, _, _ = gradient_boost_groupKFold(number_of_splits=number_of_splits,\n",
    "                                                        model=model,\n",
    "                                                        X_train=X_train, \n",
    "                                                        y_train=y_train_log\n",
    "                                                        )\n",
    "print(\"Average score\", average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91d5dda5-7e6d-42b8-a871-df9bc78382fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(\n",
    "            n_estimators = optimal_n_estimators*10,\n",
    "            max_depth = optimal_max_depth,\n",
    "            min_samples_split = optimal_min_samples_split,\n",
    "            min_samples_leaf = optimal_min_samples_leaf,\n",
    "            max_features = optimal_max_features,\n",
    "            subsample = optimal_subsample,\n",
    "            learning_rate = original_learning_rate / 10,\n",
    "            loss = 'squared_error',\n",
    "            criterion = 'squared_error',\n",
    "            verbose = 0,\n",
    "            warm_start = False,\n",
    "            random_state = random_state,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c94fca45-b9a2-4ca5-b066-b87adec9fbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting on split  1  of cross validation\n",
      "starting on split  2  of cross validation\n",
      "starting on split  3  of cross validation\n",
      "starting on split  4  of cross validation\n",
      "starting on split  5  of cross validation\n",
      "Average score 0.2012627170450033\n"
     ]
    }
   ],
   "source": [
    "scores, average_score, _, _ = gradient_boost_groupKFold(number_of_splits=number_of_splits,\n",
    "                                                        model=model,\n",
    "                                                        X_train=X_train, \n",
    "                                                        y_train=y_train_log\n",
    "                                                        )\n",
    "print(\"Average score\", average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b02685ca-af7b-4604-aa5c-8f93268ef4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_and_store(model, test_labels, test_labels, path=\".\\submissions\\GB3.0.csv\", exponential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b093113c-3c13-4688-9dd1-d1662c2f3b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(criterion='squared_error', learning_rate=0.01,\n",
       "                          max_depth=13, max_features=40, min_samples_leaf=40,\n",
       "                          min_samples_split=1000, n_estimators=3000,\n",
       "                          random_state=1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "519fbbd6-76eb-40df-9c2e-96a5f9a48200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17.03487266, 16.99316861, 17.72845302, ..., 15.96179278,\n",
       "       16.27841316, 15.81672909])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71206f96-3782-4fda-a006-b2d624f59259",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
